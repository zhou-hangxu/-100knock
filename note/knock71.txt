単純な一層のニューラルネットワーク（Single Layer Perceptron）を定義しています。
まず、torch.nn.Moduleを継承して（けいしょう）Netというクラスを作成しています。

super:  親クラスのnn.Moduleの初期化メソッドを呼び出しています。
self.fcは、輸入層から輸出層までの線形変換を表す。
　biasパラメータはバイアス項を使わない。
nn.init.normal_は、重みを正規分布（平均0.0、標準偏差1.0）の乱数で初期化するための関数です。

入力xをself.fcに通して線形変換を行い、結果を返します。入力xを受け取り、順伝播の結果xを返します。

クラスのインスタンスmodelを作成しています。
modelの入力次元は300であり、出力サイズは4です

modelにX_trainの最初の要素を入力して、ソフトマックス関数を適用して確率分布を得ます。
dim=-1は、最後の次元（最後の次元がクラス次元である場合）を基準にソフトマックス関数を適用することを意味します。

Y: 最初から4つの要素